{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwArhPMTfZE/5QBrnzxGyB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garciasergio94y/TFM/blob/main/Pyramidal_RNN_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación y carga de librerías:\n",
        "\n",
        "packages <- c(\"readr\", \"dplyr\", \"caret\", \"tensorflow\", \"tfdatasets\", \"keras\")\n",
        "\n",
        "# Función para instalar paquetes si no están ya instalados\n",
        "install_packages <- function(package) {\n",
        "  if (!require(package, character.only = TRUE)) {\n",
        "    install.packages(package)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Aplicar la función para cada uno de los paquetes\n",
        "lapply(packages, install_packages)\n",
        "\n",
        "require(readr)\n",
        "require(dplyr)\n",
        "require(caret)\n",
        "require(tensorflow)\n",
        "require(keras)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcKncLefo322",
        "outputId": "ee5fca9b-e447-4c0b-e939-cf94070ead45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: readr\n",
            "\n",
            "Loading required package: dplyr\n",
            "\n",
            "\n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n",
            "Loading required package: caret\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘caret’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘listenv’, ‘parallelly’, ‘future’, ‘globals’, ‘shape’, ‘future.apply’, ‘numDeriv’, ‘progressr’, ‘SQUAREM’, ‘diagram’, ‘lava’, ‘prodlim’, ‘proxy’, ‘iterators’, ‘Rcpp’, ‘clock’, ‘gower’, ‘hardhat’, ‘ipred’, ‘timeDate’, ‘e1071’, ‘foreach’, ‘ModelMetrics’, ‘plyr’, ‘pROC’, ‘recipes’, ‘reshape2’\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensorflow::tf_gpu_configured()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "XM3iSvsm8ZNO",
        "outputId": "4667ed62-b7b6-4171-af45-218d66a2a464"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow built with CUDA:  TRUE \n",
            "GPU device name:  /device:GPU:0"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "TRUE"
            ],
            "text/markdown": "TRUE",
            "text/latex": "TRUE",
            "text/plain": [
              "[1] TRUE"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EhDKsGXewWe",
        "outputId": "539c4d7c-82e2-4129-c372-b61f05af83d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message in write.csv(dataset, file = \"dataset\", row.names = F, col.names = F):\n",
            "“attempt to set 'col.names' ignored”\n"
          ]
        }
      ],
      "source": [
        "# Leer archivo dataset desde Github:\n",
        "url <- \"https://raw.githubusercontent.com/garciasergio94y/TFM/pyramidal_RNN/Resultados/dataset?token=GHSAT0AAAAAACCAWAK5TXDVVN4TPHC4WDVKZCODIDA\"\n",
        "dataset <- read.csv(url)\n",
        "# Guardar una copia local:\n",
        "write.csv(dataset, file = \"dataset\", row.names = F, col.names = F) \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir fechas en formato POSIXct:\n",
        "dataset[,1] %<>% as.POSIXct()"
      ],
      "metadata": {
        "id": "ABzL8R-64mKf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecer puntos de corte para training y validation sets:\n",
        "\n",
        "time_point_50 <- as.POSIXct(as.Date(quantile(dataset[,1], 0.5)))\n",
        "\n",
        "time_point_75 <- as.POSIXct(as.Date(quantile(dataset[,1], 0.75)))\n",
        "\n",
        "time_point_50\n",
        "time_point_75"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "83NtXb2ht_h3",
        "outputId": "014ef6e7-dcd2-4849-f228-0e0fb8bad13f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             50% \n",
              "\"2022-11-08 UTC\" "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             75% \n",
              "\"2022-12-23 UTC\" "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestra de entrenamiento:\n",
        "train <- dataset %>%\n",
        "  subset(dataset[,1] <= time_point_50)\n",
        "\n",
        "  table(train$CTRL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "eZwFzC3RuRoS",
        "outputId": "e39edf65-88c0-4340-9500-a5e5a519fbb0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "    0     1 \n",
              "53928   926 "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversión a factores de las variables categóricas:\n",
        "# Obtener índices de las columnas numéricas que no son \"resultado\" o empiezan por \"W\"\n",
        "new_train <- train\n",
        "\n",
        "# Transformar columnas numéricas a factores\n",
        "new_train$CTRL %<>% as.factor()\n",
        "\n",
        "# Upsampling del dataset de training de la clase minoritaria\n",
        "\"%ni%\" <- Negate(\"%in%\")\n",
        "train_bal <- caret::upSample(\n",
        "  x = new_train[,colnames(new_train) %ni% \"CTRL\"], \n",
        "  y = new_train$CTRL)\n",
        "names(train_bal)[ncol(train_bal)] <- \"CTRL\"\n",
        "\n",
        "# Devolver los factores a variable numérica: \n",
        "\n",
        "train_bal$CTRL %<>% as.numeric()\n",
        "\n",
        "new_train <- train_bal\n",
        "\n",
        "table(new_train$CTRL)\n",
        "\n",
        "# Muestra de validación:\n",
        "val <- dataset %>%\n",
        "  subset(dataset[,1] > time_point_50 &\n",
        "           dataset[,1] <= time_point_75)\n",
        "\n",
        "# Muestra de test:\n",
        "test <- dataset %>%\n",
        "  subset(dataset[,1] > time_point_75)"
      ],
      "metadata": {
        "id": "5mAR0SWs5pTH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "173c3196-5924-434a-a5a9-e3d0fe4a37b6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "    1     2 \n",
              "53928 53928 "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función parar crear un array con inputs y targets. Se excluye la columna de tiempos:\n",
        "input_data_colnames <- names(new_train) %>%\n",
        "  setdiff(c(\"TIEMPO_MUESTRA\"))\n",
        "\n",
        "df_to_inputs_and_targets <- function(df) {\n",
        "  inputs <- df[input_data_colnames] %>%\n",
        "    as.matrix()\n",
        "  targets <- as.numeric(as.character(df$CTRL))\n",
        "  list(inputs, targets)\n",
        "}\n",
        "\n",
        "#Función para calcular el sequence_length a partir del promedio de muestras diarias: \n",
        "seq_length <- function(df) {\n",
        "  date <- as.Date(df$TIEMPO_MUESTRA)\n",
        "  day_obs <- aggregate(x = df$TIEMPO_MUESTRA, by = list(date),\n",
        "                       FUN = length)\n",
        "  mean_day_obs <- round(mean(day_obs[, 2]))\n",
        "  return(mean_day_obs)\n",
        "}\n",
        "\n",
        "#Función para crear el dataset:\n",
        "sampling_rate <- 1    \n",
        "sequence_length <- seq_length(new_train)\n",
        "batch_size <- 256\n",
        "make_dataset <- function(df) {\n",
        "  c(inputs, targets) %<-% df_to_inputs_and_targets(df)\n",
        "  timeseries_dataset_from_array(inputs, targets,\n",
        "                                sampling_rate = sampling_rate,\n",
        "                                sequence_length = sequence_length,\n",
        "                                shuffle = FALSE,\n",
        "                                batch_size = batch_size) \n",
        "}\n",
        "\n",
        "train_ds <- make_dataset(new_train) %>%\n",
        "  dataset_map(function(x, y) list(x, keras::k_expand_dims(y)))\n",
        "  \n",
        "test_ds <- make_dataset(test) %>%\n",
        "  dataset_map(function(x, y) list(x, keras::k_expand_dims(y)))\n",
        "\n",
        "val_ds <- make_dataset(val) %>%\n",
        "  dataset_map(function(x, y) list(x, keras::k_expand_dims(y)))\n"
      ],
      "metadata": {
        "id": "eAOcJ4F8faIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la arquitectura de la red neuronal (Long short-term        memory) :\n",
        "# Número de variables a entrenar:\n",
        "ncol_input_data <- length(input_data_colnames)\n",
        "# Capas de entrada y de salida:\n",
        "inputs <- layer_input(shape = c(sequence_length, ncol_input_data)) \n",
        "outputs <- inputs %>%\n",
        "  layer_conv_1d(filters = 16, kernel_size = 3, \n",
        "                activation = \"relu\") %>%\n",
        "  layer_max_pooling_1d(pool_size = 2) %>%\n",
        "  layer_lstm(units = 16) %>%\n",
        "  layer_dropout(rate = 0.5) %>%\n",
        "  layer_dense(units = 1, activation = \"sigmoid\") \n",
        "model_5 <- keras_model(inputs, outputs) \n",
        "\n",
        "# Definir callbacks para guardar el mejor modelo:\n",
        "callbacks <- list(\n",
        "  callback_model_checkpoint(file.path(resultsdir, \"lstm_5.keras\",\n",
        "                                     save_best_only = TRUE))) \n",
        "\n",
        "# Función para calcular F1 como métrica para el modelo:\n",
        "  f1_score <- function(y_true, y_pred) {\n",
        "  true_positives <- sum(backend()$round(backend()$clip(y_true * y_pred, 0, 1)))\n",
        "  possible_positives <- sum(backend()$round(backend()$clip(y_true, 0, 1)))\n",
        "  predicted_positives <- sum(backend()$round(backend()$clip(y_pred, 0, 1)))\n",
        "  precision <- true_positives / (predicted_positives + backend()$epsilon())\n",
        "  recall <- true_positives / (possible_positives + backend()$epsilon())\n",
        "  f1_score <- 2 * precision * recall / (precision + recall + backend()$epsilon())\n",
        "  return(f1_score)\n",
        "}\n",
        "\n",
        "\n",
        "# Compilar el modelo:\n",
        "model_5 %>% compile(optimizer = \"adam\",\n",
        "                  loss = \"binary_crossentropy\",\n",
        "                  metrics = list(\"binary_accuracy\", f1_score)) \n",
        " \n",
        "# Entrenar el modelo:\n",
        "history_5 <- model_5 %>%\n",
        "  fit(train_ds, epochs = 100, validation_data = val_ds,\n",
        "      callbacks = callbacks)"
      ],
      "metadata": {
        "id": "MaMmjDpDfbzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qpumk6DQKTcZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}