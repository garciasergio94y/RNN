{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garciasergio94y/RNN/blob/LSTM_onehot_QC/LSTM_onehot_QC_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fcKncLefo322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "06f6316e-3990-4082-9708-540274595f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: tensorflow\n",
            "\n",
            "Loading required package: keras\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<ol>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "\t<li>NULL</li>\n",
              "</ol>\n"
            ],
            "text/markdown": "1. NULL\n2. NULL\n3. NULL\n4. NULL\n5. NULL\n6. NULL\n7. NULL\n8. NULL\n9. NULL\n10. NULL\n11. NULL\n12. NULL\n13. NULL\n14. NULL\n15. NULL\n16. NULL\n17. NULL\n\n\n",
            "text/latex": "\\begin{enumerate}\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\item NULL\n\\end{enumerate}\n",
            "text/plain": [
              "[[1]]\n",
              "NULL\n",
              "\n",
              "[[2]]\n",
              "NULL\n",
              "\n",
              "[[3]]\n",
              "NULL\n",
              "\n",
              "[[4]]\n",
              "NULL\n",
              "\n",
              "[[5]]\n",
              "NULL\n",
              "\n",
              "[[6]]\n",
              "NULL\n",
              "\n",
              "[[7]]\n",
              "NULL\n",
              "\n",
              "[[8]]\n",
              "NULL\n",
              "\n",
              "[[9]]\n",
              "NULL\n",
              "\n",
              "[[10]]\n",
              "NULL\n",
              "\n",
              "[[11]]\n",
              "NULL\n",
              "\n",
              "[[12]]\n",
              "NULL\n",
              "\n",
              "[[13]]\n",
              "NULL\n",
              "\n",
              "[[14]]\n",
              "NULL\n",
              "\n",
              "[[15]]\n",
              "NULL\n",
              "\n",
              "[[16]]\n",
              "NULL\n",
              "\n",
              "[[17]]\n",
              "NULL\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Instalación y carga de librerías:\n",
        "\n",
        "packages <- c(\"readr\", \"readxl\", \"purrr\", \"dplyr\", \"filesstrings\",\n",
        "              \"stringr\", \"tidyr\", \"lubridate\", \"ggplot2\", \"tictoc\",\n",
        "               \"wavelets\", \"reticulate\", \"abind\",\n",
        "              \"tensorflow\", \"tfdatasets\", \"keras\", \"tfruns\")\n",
        "\n",
        "\n",
        "# Función para instalar paquetes si no están ya instalados\n",
        "install_packages <- function(package) {\n",
        "  if (!require(package, character.only = TRUE)) {\n",
        "    install.packages(package)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Aplicar la función para cada uno de los paquetes\n",
        "lapply(packages, install_packages)\n",
        "\n",
        "require(readr)\n",
        "require(readxl)\n",
        "require(purrr)\n",
        "require(dplyr)\n",
        "require(filesstrings)\n",
        "require(stringr)\n",
        "require(tidyr)\n",
        "require(lubridate)\n",
        "require(ggplot2)\n",
        "require(wavelets)\n",
        "require(tictoc)\n",
        "require(reticulate)\n",
        "require(abind)\n",
        "require(tfdatasets)\n",
        "require(tfruns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#devtools::install_github(\"rstudio/keras\")\n",
        "#devtools::install_github(\"rstudio/tensorflow\")\n",
        "#system(\"apt-get install -y libmagick++-dev\")\n",
        "#devtools::install_github('EagerAI/kerastuneR')\n",
        "#library(keras)\n",
        "#library(tensorflow)\n",
        "#library(kerastuneR)\n",
        "#system(\"pip install keras-tuner\")\n",
        "#install_keras()\n",
        "#install_tensorflow()\n",
        "#install_kerastuner()\n",
        "#require(tensorflow)\n",
        "#require(keras)\n",
        "#require(kerastuneR)"
      ],
      "metadata": {
        "id": "tqsBqhu60mom"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workingdir <- getwd()\n",
        "datadir <- file.path(workingdir, \"Datos/daily_s\")\n",
        "eventdir <- file.path(workingdir, \"Datos/daily_s/Event\")\n",
        "eventdir_old <- file.path(workingdir, \"Datos/daily_s/Event/old\")\n",
        "lotdir <- file.path(workingdir, \"Datos/daily_s/Lot\")\n",
        "lotdir_old <- file.path(workingdir, \"Datos/daily_s/Lot/old\")\n",
        "qcdir <- file.path(workingdir, \"Datos/daily_s/qc\")\n",
        "qcdir_old <- file.path(workingdir, \"Datos/daily_s/qc/old\")\n",
        "resultsdir <- file.path(workingdir, \"Resultados\")"
      ],
      "metadata": {
        "id": "CmX65urDjO83"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XM3iSvsm8ZNO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a50050a0-86af-4cdd-9c89-ac9eb6f82b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow built with CUDA:  TRUE \n",
            "GPU device name:  /device:GPU:0"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "TRUE"
            ],
            "text/markdown": "TRUE",
            "text/latex": "TRUE",
            "text/plain": [
              "[1] TRUE"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "tensorflow::tf_gpu_configured()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lectura de archivos de datos"
      ],
      "metadata": {
        "id": "iGT314P3vtdx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8EhDKsGXewWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c76ae06-6b38-495c-a724-1ae894e6d2b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message in write.csv(qc_data_sel_wl, file = \"qc_data_sel_wl\", row.names = F, :\n",
            "“attempt to set 'col.names' ignored”\n"
          ]
        }
      ],
      "source": [
        "# Leer archivo dataset desde Github:\n",
        "url <- \"https://raw.githubusercontent.com/garciasergio94y/RNN/LSTM_onehot_QC/Resultados/qc_data_sel_wl?token=GHSAT0AAAAAACDFXH5LJ7YOBL4BSAL5E4BKZDT5OMA\"\n",
        "qc_data_sel_wl <- read.csv(url)\n",
        "\n",
        "# Guardar una copia local:\n",
        "write.csv(qc_data_sel_wl, file = \"qc_data_sel_wl\", row.names = F, col.names = F)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ABzL8R-64mKf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "57a78340-cd92-4ab9-bd55-6fed8d0b0d18"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 20</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>TIEMPO_QC</th><th scope=col>QC_RESULT</th><th scope=col>W1</th><th scope=col>W2</th><th scope=col>W3</th><th scope=col>W4</th><th scope=col>W5</th><th scope=col>W6</th><th scope=col>W7</th><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th><th scope=col>V7</th><th scope=col>ANALIZADOR</th><th scope=col>CODIGO_PRUEBA</th><th scope=col>NOMBRE_PRUEBA</th><th scope=col>NIVEL</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>2022-03-01 10:15:32</td><td>0.756</td><td> -5.256767</td><td>  4.635973</td><td>-7.0963537</td><td>-1.4089131</td><td>-2.831461</td><td>-0.020687059</td><td>-0.13798708</td><td>12.543821</td><td> 8.963229</td><td> 9.883923</td><td>13.48489</td><td>11.05025</td><td>11.17946</td><td>12.40968</td><td>DXI800 num 1</td><td>CLC00033</td><td>Tirotropina #TSH</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>2022-03-01 09:58:44</td><td>0.750</td><td> -1.088411</td><td> -7.365680</td><td>-7.5892368</td><td>-0.6040175</td><td>-2.930563</td><td>-0.008832360</td><td>-0.12566793</td><td>15.921489</td><td>14.190394</td><td>10.460782</td><td>13.38209</td><td>11.16218</td><td>11.17760</td><td>12.40045</td><td>DXI800 num 1</td><td>CLC00033</td><td>Tirotropina #TSH</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>2022-03-01 09:13:08</td><td>0.707</td><td> 15.077506</td><td>-12.447274</td><td>-4.9952082</td><td> 0.2075476</td><td>-2.966887</td><td> 0.002063882</td><td>-0.11341338</td><td> 6.735010</td><td>19.529842</td><td>11.033837</td><td>13.25855</td><td>11.27737</td><td>11.17604</td><td>12.39136</td><td>DXI800 num 1</td><td>CLC00033</td><td>Tirotropina #TSH</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>2022-03-01 10:19:17</td><td>6.021</td><td>-10.178506</td><td> -5.118902</td><td>-0.4112897</td><td> 0.8945995</td><td>-2.937938</td><td> 0.011821657</td><td>-0.10126206</td><td> 6.186578</td><td>22.231911</td><td>11.437126</td><td>13.11262</td><td>11.39455</td><td>11.17477</td><td>12.38243</td><td>DXI800 num 1</td><td>CLC00033</td><td>Tirotropina #TSH</td><td>2</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>2022-03-01 10:00:05</td><td>5.943</td><td> -8.716737</td><td>  9.917385</td><td> 3.8427090</td><td> 1.4175981</td><td>-2.846321</td><td> 0.020160724</td><td>-0.08926708</td><td>16.988792</td><td>21.659853</td><td>11.613726</td><td>12.94885</td><td>11.51263</td><td>11.17377</td><td>12.37365</td><td>DXI800 num 1</td><td>CLC00033</td><td>Tirotropina #TSH</td><td>2</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>2022-03-01 09:15:14</td><td>5.882</td><td> 17.989157</td><td> 15.769433</td><td> 5.8808384</td><td> 1.7764004</td><td>-2.695368</td><td> 0.026389251</td><td>-0.07752756</td><td>22.532139</td><td>18.725006</td><td>11.632671</td><td>12.77329</td><td>11.63037</td><td>11.17306</td><td>12.36503</td><td>DXI800 num 1</td><td>CLC00033</td><td>Tirotropina #TSH</td><td>2</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA data.frame: 6 × 20\n\n| <!--/--> | TIEMPO_QC &lt;dttm&gt; | QC_RESULT &lt;dbl&gt; | W1 &lt;dbl&gt; | W2 &lt;dbl&gt; | W3 &lt;dbl&gt; | W4 &lt;dbl&gt; | W5 &lt;dbl&gt; | W6 &lt;dbl&gt; | W7 &lt;dbl&gt; | V1 &lt;dbl&gt; | V2 &lt;dbl&gt; | V3 &lt;dbl&gt; | V4 &lt;dbl&gt; | V5 &lt;dbl&gt; | V6 &lt;dbl&gt; | V7 &lt;dbl&gt; | ANALIZADOR &lt;chr&gt; | CODIGO_PRUEBA &lt;chr&gt; | NOMBRE_PRUEBA &lt;chr&gt; | NIVEL &lt;chr&gt; |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | 2022-03-01 10:15:32 | 0.756 |  -5.256767 |   4.635973 | -7.0963537 | -1.4089131 | -2.831461 | -0.020687059 | -0.13798708 | 12.543821 |  8.963229 |  9.883923 | 13.48489 | 11.05025 | 11.17946 | 12.40968 | DXI800 num 1 | CLC00033 | Tirotropina #TSH | 1 |\n| 2 | 2022-03-01 09:58:44 | 0.750 |  -1.088411 |  -7.365680 | -7.5892368 | -0.6040175 | -2.930563 | -0.008832360 | -0.12566793 | 15.921489 | 14.190394 | 10.460782 | 13.38209 | 11.16218 | 11.17760 | 12.40045 | DXI800 num 1 | CLC00033 | Tirotropina #TSH | 1 |\n| 3 | 2022-03-01 09:13:08 | 0.707 |  15.077506 | -12.447274 | -4.9952082 |  0.2075476 | -2.966887 |  0.002063882 | -0.11341338 |  6.735010 | 19.529842 | 11.033837 | 13.25855 | 11.27737 | 11.17604 | 12.39136 | DXI800 num 1 | CLC00033 | Tirotropina #TSH | 1 |\n| 4 | 2022-03-01 10:19:17 | 6.021 | -10.178506 |  -5.118902 | -0.4112897 |  0.8945995 | -2.937938 |  0.011821657 | -0.10126206 |  6.186578 | 22.231911 | 11.437126 | 13.11262 | 11.39455 | 11.17477 | 12.38243 | DXI800 num 1 | CLC00033 | Tirotropina #TSH | 2 |\n| 5 | 2022-03-01 10:00:05 | 5.943 |  -8.716737 |   9.917385 |  3.8427090 |  1.4175981 | -2.846321 |  0.020160724 | -0.08926708 | 16.988792 | 21.659853 | 11.613726 | 12.94885 | 11.51263 | 11.17377 | 12.37365 | DXI800 num 1 | CLC00033 | Tirotropina #TSH | 2 |\n| 6 | 2022-03-01 09:15:14 | 5.882 |  17.989157 |  15.769433 |  5.8808384 |  1.7764004 | -2.695368 |  0.026389251 | -0.07752756 | 22.532139 | 18.725006 | 11.632671 | 12.77329 | 11.63037 | 11.17306 | 12.36503 | DXI800 num 1 | CLC00033 | Tirotropina #TSH | 2 |\n\n",
            "text/latex": "A data.frame: 6 × 20\n\\begin{tabular}{r|llllllllllllllllllll}\n  & TIEMPO\\_QC & QC\\_RESULT & W1 & W2 & W3 & W4 & W5 & W6 & W7 & V1 & V2 & V3 & V4 & V5 & V6 & V7 & ANALIZADOR & CODIGO\\_PRUEBA & NOMBRE\\_PRUEBA & NIVEL\\\\\n  & <dttm> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr> & <chr> & <chr> & <chr>\\\\\n\\hline\n\t1 & 2022-03-01 10:15:32 & 0.756 &  -5.256767 &   4.635973 & -7.0963537 & -1.4089131 & -2.831461 & -0.020687059 & -0.13798708 & 12.543821 &  8.963229 &  9.883923 & 13.48489 & 11.05025 & 11.17946 & 12.40968 & DXI800 num 1 & CLC00033 & Tirotropina \\#TSH & 1\\\\\n\t2 & 2022-03-01 09:58:44 & 0.750 &  -1.088411 &  -7.365680 & -7.5892368 & -0.6040175 & -2.930563 & -0.008832360 & -0.12566793 & 15.921489 & 14.190394 & 10.460782 & 13.38209 & 11.16218 & 11.17760 & 12.40045 & DXI800 num 1 & CLC00033 & Tirotropina \\#TSH & 1\\\\\n\t3 & 2022-03-01 09:13:08 & 0.707 &  15.077506 & -12.447274 & -4.9952082 &  0.2075476 & -2.966887 &  0.002063882 & -0.11341338 &  6.735010 & 19.529842 & 11.033837 & 13.25855 & 11.27737 & 11.17604 & 12.39136 & DXI800 num 1 & CLC00033 & Tirotropina \\#TSH & 1\\\\\n\t4 & 2022-03-01 10:19:17 & 6.021 & -10.178506 &  -5.118902 & -0.4112897 &  0.8945995 & -2.937938 &  0.011821657 & -0.10126206 &  6.186578 & 22.231911 & 11.437126 & 13.11262 & 11.39455 & 11.17477 & 12.38243 & DXI800 num 1 & CLC00033 & Tirotropina \\#TSH & 2\\\\\n\t5 & 2022-03-01 10:00:05 & 5.943 &  -8.716737 &   9.917385 &  3.8427090 &  1.4175981 & -2.846321 &  0.020160724 & -0.08926708 & 16.988792 & 21.659853 & 11.613726 & 12.94885 & 11.51263 & 11.17377 & 12.37365 & DXI800 num 1 & CLC00033 & Tirotropina \\#TSH & 2\\\\\n\t6 & 2022-03-01 09:15:14 & 5.882 &  17.989157 &  15.769433 &  5.8808384 &  1.7764004 & -2.695368 &  0.026389251 & -0.07752756 & 22.532139 & 18.725006 & 11.632671 & 12.77329 & 11.63037 & 11.17306 & 12.36503 & DXI800 num 1 & CLC00033 & Tirotropina \\#TSH & 2\\\\\n\\end{tabular}\n",
            "text/plain": [
              "  TIEMPO_QC           QC_RESULT W1         W2         W3         W4        \n",
              "1 2022-03-01 10:15:32 0.756      -5.256767   4.635973 -7.0963537 -1.4089131\n",
              "2 2022-03-01 09:58:44 0.750      -1.088411  -7.365680 -7.5892368 -0.6040175\n",
              "3 2022-03-01 09:13:08 0.707      15.077506 -12.447274 -4.9952082  0.2075476\n",
              "4 2022-03-01 10:19:17 6.021     -10.178506  -5.118902 -0.4112897  0.8945995\n",
              "5 2022-03-01 10:00:05 5.943      -8.716737   9.917385  3.8427090  1.4175981\n",
              "6 2022-03-01 09:15:14 5.882      17.989157  15.769433  5.8808384  1.7764004\n",
              "  W5        W6           W7          V1        V2        V3        V4      \n",
              "1 -2.831461 -0.020687059 -0.13798708 12.543821  8.963229  9.883923 13.48489\n",
              "2 -2.930563 -0.008832360 -0.12566793 15.921489 14.190394 10.460782 13.38209\n",
              "3 -2.966887  0.002063882 -0.11341338  6.735010 19.529842 11.033837 13.25855\n",
              "4 -2.937938  0.011821657 -0.10126206  6.186578 22.231911 11.437126 13.11262\n",
              "5 -2.846321  0.020160724 -0.08926708 16.988792 21.659853 11.613726 12.94885\n",
              "6 -2.695368  0.026389251 -0.07752756 22.532139 18.725006 11.632671 12.77329\n",
              "  V5       V6       V7       ANALIZADOR   CODIGO_PRUEBA NOMBRE_PRUEBA    NIVEL\n",
              "1 11.05025 11.17946 12.40968 DXI800 num 1 CLC00033      Tirotropina #TSH 1    \n",
              "2 11.16218 11.17760 12.40045 DXI800 num 1 CLC00033      Tirotropina #TSH 1    \n",
              "3 11.27737 11.17604 12.39136 DXI800 num 1 CLC00033      Tirotropina #TSH 1    \n",
              "4 11.39455 11.17477 12.38243 DXI800 num 1 CLC00033      Tirotropina #TSH 2    \n",
              "5 11.51263 11.17377 12.37365 DXI800 num 1 CLC00033      Tirotropina #TSH 2    \n",
              "6 11.63037 11.17306 12.36503 DXI800 num 1 CLC00033      Tirotropina #TSH 2    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Convertir fechas en formato POSIXct y niveles de QC en chr:\n",
        "\n",
        "qc_data_sel_wl[,1] %<>% as.POSIXct(tz = \"Europe/Madrid\")\n",
        "qc_data_sel_wl$NIVEL %<>% as.character()\n",
        "head(qc_data_sel_wl)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definición de funciones para transformación de variables, normalización y secuenciación de series de datos:"
      ],
      "metadata": {
        "id": "mMi3X0OGv3k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de normalización de las variables continuas y eliminación de coeficientes wavelet con valores NA. Se definen dos funciones, una para el set de training y otra para los sets de test y validación. La diferencia es que la de train devuelve vectores de medias y de desviaciones estándar que luego se usan como argumentos en las otras. De esta forma, el escalado y normalización se realiza con la misma media y desviación del set de entrenamiento para los otros dos datasets:\n",
        "\n",
        "normalize_train <- function(data) {\n",
        "\n",
        "  # Identificar las columnas que empiezan por W y la columna 'RESULTADO'\n",
        "  wavelet_cols <- grep(\"^[WV]\", colnames(data), value = TRUE)\n",
        "  result_col <- \"QC_RESULT\"\n",
        "\n",
        "  # Calcular medias y desviaciones estándar por grupos de pruebas y   analizador:\n",
        "  means <- data %>%\n",
        "    group_by(ANALIZADOR, CODIGO_PRUEBA) %>%\n",
        "    summarise(across(c(result_col, wavelet_cols),\n",
        "                     ~mean(., na.rm = T)))\n",
        "\n",
        "  std_devs <- data %>%\n",
        "    group_by(ANALIZADOR, CODIGO_PRUEBA) %>%\n",
        "    summarise(across(c(result_col, wavelet_cols),\n",
        "                     ~sd(., na.rm = T)))\n",
        "\n",
        "  # Normalizar las columnas de resultado y coeficientes wavelet\n",
        "  norm_data <- data %>%\n",
        "    group_by(ANALIZADOR, CODIGO_PRUEBA) %>%\n",
        "    mutate(across(c(result_col, wavelet_cols), scale))%>%\n",
        "    mutate(across(wavelet_cols,\n",
        "                           ~ifelse(is.na(.), -99999, .))) %>%\n",
        "    ungroup()\n",
        "\n",
        "  # Devolver el dataframe escalado y las medias y desviaciones estándar:\n",
        "\n",
        "  return(list(scaled_data = as.data.frame(norm_data),\n",
        "              means = means, stdev = std_devs))\n",
        "}"
      ],
      "metadata": {
        "id": "o0ZlcpJTv4M0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función de normalización para los datos de validación y test, con eliminación de valores NA en los wavelets:\n",
        "\n",
        "norm_test_val <- function(data, means, stds) {\n",
        "\n",
        "  # Identificar las columnas numéricas y seleccionarlas\n",
        "  wavelet_cols <- grep(\"^[WV]\", colnames(data), value = TRUE)\n",
        "  result_col <- \"QC_RESULT\"\n",
        "  test_cols <- \"CODIGO_PRUEBA\"\n",
        "\n",
        "  cols <- c(result_col, wavelet_cols, test_cols)\n",
        "\n",
        "  # Seleccionar medias y desviaciones de resultados y coeficientes   wavelet:\n",
        "  means_r <- train_n$means\n",
        "  stds_r <- train_n$stdev\n",
        "  means_wl <- train_n$means[wavelet_cols]\n",
        "  stds_wl <- train_n$stdev[wavelet_cols]\n",
        "\n",
        "  # Normalizar por cada prueba las columnas de resultado y coeficientes wavelet usando las medias y desviaciones estándar de train suministradas:\n",
        "  means <- data %>%\n",
        "    group_by(ANALIZADOR, CODIGO_PRUEBA) %>%\n",
        "    left_join(means_r, by = c(\"ANALIZADOR\", \"CODIGO_PRUEBA\"),\n",
        "              suffix = c(\".val\", \".means\")) %>%\n",
        "     ungroup()\n",
        "\n",
        "  stds <- data %>%\n",
        "    group_by(ANALIZADOR, CODIGO_PRUEBA) %>%\n",
        "     left_join(stds_r, by = c(\"ANALIZADOR\", \"CODIGO_PRUEBA\"),\n",
        "               suffix = c(\".val\", \".sd\")) %>%\n",
        "    ungroup()\n",
        "\n",
        "\n",
        "  norm_data <- data %>%\n",
        "    mutate(., RESULTADO.st =\n",
        "             (.[,result_col]-\n",
        "                select(means,\n",
        "                       starts_with(result_col) &\n",
        "                       ends_with(\".means\"))) /\n",
        "                select(stds,\n",
        "                       starts_with(result_col) &\n",
        "                       ends_with(\".sd\"))\n",
        "           ) %>%\n",
        "    mutate(WAVELETS.st =\n",
        "             across(all_of(wavelet_cols),\n",
        "                    ~ (. - select(means,\n",
        "                                  starts_with(cur_column()) &\n",
        "                                    ends_with(\".means\"))[[1]]) /\n",
        "                      select(stds,\n",
        "                             starts_with(cur_column()) &\n",
        "                               ends_with(\".sd\"))[[1]])\n",
        "           ) %>%\n",
        "    select(-c(result_col, wavelet_cols)) %>%\n",
        "    unnest(c(WAVELETS.st, RESULTADO.st)) %>%\n",
        "    relocate(starts_with(\"QC_\"), .after = 1) %>%\n",
        "    relocate(starts_with(\"W\"), .after = 2) %>%\n",
        "    relocate(starts_with(\"V\"), .before = ANALIZADOR)\n",
        "\n",
        "  names(norm_data)[2]<-result_col\n",
        "\n",
        "  return(as.data.frame(norm_data))\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "nLqSx55RwUDM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Función ```code_cat_var```.\n",
        "\n",
        "Función para convertir las variables categóricas tipo string en vectores numéricos y codificarlas (one hot), así como normalizar los valores de las variables continuas, creando una lista que retiene en un vector la información de los niveles de los factores"
      ],
      "metadata": {
        "id": "Gjbp70bou5RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "code_cat_var <- function(data) {\n",
        "  # Eliminación de la columna CODIGO_PRUEBA si solo tiene una          categoría:\n",
        "  if(length(unique(data$CODIGO_PRUEBA))==1){\n",
        "    data %<>% select(., -CODIGO_PRUEBA)\n",
        "    }\n",
        "\n",
        "\n",
        "  # Detección de strings:\n",
        "  cat_vars <- which(sapply(data, is.character))\n",
        "  # Conversión a factores:\n",
        "  data_cat <- lapply(data[,cat_vars], as.factor)\n",
        "  # Extracción de niveles:\n",
        "  levels <- lapply(data_cat, levels)\n",
        "\n",
        "  # Codificar one-hot todas las variables factor:\n",
        "  encoded_cols <- lapply(seq_along(data_cat), function(i) {\n",
        "    cols <- model.matrix(~ factor(data_cat[[i]]) - 1)\n",
        "    colnames(cols) <- paste0(names(data)[cat_vars[i]], \"_\",\n",
        "                             levels[[i]])\n",
        "    cols\n",
        "    })\n",
        "\n",
        "  # Unir columnas codificadas con conjunto de datos original:\n",
        "  if (!\"CODIGO_PRUEBA\" %in% names(data)) {\n",
        "    data_encoded <- bind_cols(data %>%\n",
        "                                select(-all_of(cat_vars)),\n",
        "                                encoded_cols)\n",
        "    } else {\n",
        "      data_encoded <-  bind_cols(data %>%\n",
        "                                   select(c(-all_of(cat_vars),\n",
        "                                            -\"CODIGO_PRUEBA\")),\n",
        "                                 encoded_cols)\n",
        "      }\n",
        "\n",
        "  return(list(data = data_encoded, levels = levels))\n",
        "}"
      ],
      "metadata": {
        "id": "DVazEu9Ouyfq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para crear un índice de casos únicos de combinaciones de ANALIZADOR, CÓDIGO_PRUEBA y NIVEL:\n",
        "\n",
        "unique_lab_cases <- function(df, categorical_vars) {\n",
        "  unique_groups <- unique(df[categorical_vars])\n",
        "\n",
        "  code <- apply(unique_groups, 1, function(row) {\n",
        "    paste0(ifelse(row == 1, 1, 0), collapse = \"\")\n",
        "  })\n",
        "  unique_groups %<>% mutate(., code)\n",
        "  coded_df <- df %>%\n",
        "    merge(unique_groups, ., by = colnames(unique_groups)\n",
        "          [-length(colnames(unique_groups))])\n",
        "  coded_df <- coded_df[, c(colnames(df), \"code\")]\n",
        "\n",
        "  return(coded_df)\n",
        "}\n"
      ],
      "metadata": {
        "id": "OIa4QAmLn5DF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "83NtXb2ht_h3"
      },
      "outputs": [],
      "source": [
        "# Función para creación de lotes de series temporales de longitud k (lookback)\n",
        "\n",
        "create_lstm_data.2 <-\n",
        "  function(data, lookback, delay, min_index, max_index,\n",
        "           shuffle = FALSE, batch_size, step = 1,\n",
        "           predseries) {\n",
        "\n",
        "  if (is.null(max_index)) max_index <- nrow(data) - delay - 1\n",
        "  i <- min_index + lookback\n",
        "  function() {\n",
        "    if (shuffle) {\n",
        "      rows <- sample(c((min_index+lookback):max_index),\n",
        "                     size = batch_size)\n",
        "    } else {\n",
        "      if (i + batch_size > max_index)\n",
        "        i <<- min_index + lookback\n",
        "      rows <- c(i:min(i+batch_size, max_index))\n",
        "      i <<- i + length(rows)\n",
        "}\n",
        "    samples <- array(0, dim = c(length(rows),\n",
        "                                lookback / step,\n",
        "                                dim(data)[[-1]]))\n",
        "    targets <- array(0, dim = c(length(rows)))\n",
        "\n",
        "    for (j in 1:length(rows)) {\n",
        "      indices <- (rows[[j]] - lookback + 1):(rows[[j]])\n",
        "      samples[j,,] <- data[indices, ]\n",
        "      targets[[j]] <- data[rows[[j]] + delay,predseries]\n",
        "    }\n",
        "    list(samples, targets)\n",
        "  }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eZwFzC3RuRoS",
        "outputId": "3be4bc74-a887-435c-a732-5c0755d9b1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             50% \n",
              "\"2022-10-04 UTC\" "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             75% \n",
              "\"2023-01-20 UTC\" "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Se divide el dataset en 50% de datos para entrenamiento, 25% para test y 25% para validación.\n",
        "# Para evitar fraccionar las unidades temporales diarias usamos percentiles de la secuencia temporal en días:\n",
        "\n",
        "time_point_50 <- as.POSIXct(as.Date(\n",
        "  quantile(qc_data_sel_wl[[1]], 0.5)))\n",
        "\n",
        "time_point_75 <- as.POSIXct(as.Date(\n",
        "  quantile(qc_data_sel_wl[[1]], 0.75)))\n",
        "\n",
        "time_point_50\n",
        "time_point_75"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestra de entrenamiento:\n",
        "train_n <- qc_data_sel_wl %>%\n",
        "  subset(.[[1]] <= time_point_75) %>%\n",
        "  # Normalización del dataset y eliminación de coeficientes\n",
        "  # wavelet con valor NA:\n",
        "  normalize_train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mfYLtiEQ8Mx",
        "outputId": "4e3deacd-bc14-4e69-e4e9-0db921544b7e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message:\n",
            "“\u001b[1m\u001b[22mThere were 2 warnings in `summarise()`.\n",
            "The first warning was:\n",
            "\u001b[1m\u001b[22m\u001b[36mℹ\u001b[39m In argument: `across(c(result_col, wavelet_cols), ~mean(., na.rm = T))`.\n",
            "Caused by warning:\n",
            "\u001b[1m\u001b[22m\u001b[33m!\u001b[39m Using an external vector in selections was deprecated in tidyselect 1.1.0.\n",
            "\u001b[36mℹ\u001b[39m Please use `all_of()` or `any_of()` instead.\n",
            "  # Was:\n",
            "  data %>% select(result_col)\n",
            "\n",
            "  # Now:\n",
            "  data %>% select(all_of(result_col))\n",
            "\n",
            "See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\n",
            "\u001b[1m\u001b[22m\u001b[36mℹ\u001b[39m Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.”\n",
            "\u001b[1m\u001b[22m`summarise()` has grouped output by 'ANALIZADOR'. You can override using the\n",
            "`.groups` argument.\n",
            "\u001b[1m\u001b[22m`summarise()` has grouped output by 'ANALIZADOR'. You can override using the\n",
            "`.groups` argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestra de validación:\n",
        "val_n <- qc_data_sel_wl %>%\n",
        "  subset(\n",
        "    #.[[1]] > time_point_50 &\n",
        "    .[[1]] > time_point_75) %>%\n",
        "  # Normalización del dataset y eliminación de coeficientes\n",
        "  # wavelet con valor NA:\n",
        "  norm_test_val(means = train_n$means, stds = train_n$stdev)"
      ],
      "metadata": {
        "id": "wpZHpUfERR-g"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestra de test:\n",
        "test <- qc_data_sel_wl %>%\n",
        "  subset(.[[1]] > time_point_75)\n",
        "  # Normalización del dataset y eliminación de coeficientes\n",
        "  # wavelet con valor NA:\n",
        "test_n <- test %>% norm_test_val(means = train_n$means, stds = train_n$stdev)"
      ],
      "metadata": {
        "id": "yCyuYseBznLA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificación onehot sin wavelets\n",
        "\n",
        "train_code <- code_cat_var(\n",
        "  train_n$scaled_data[,-c(3:16, 19)])\n",
        "\n",
        "val_code <- code_cat_var(val_n[,-c(3:16, 19)])\n",
        "\n",
        "test_code <- code_cat_var(test_n[,-c(3:16, 19)])"
      ],
      "metadata": {
        "id": "Uslvv9N9yIB0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creación de las funciones generadoras para las series temporales etiquetadas de los datasets de training, validación y prueba, y de sus correspondientes funciones envolventes o wrapper."
      ],
      "metadata": {
        "id": "oWJM22CnxQYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data <- as.matrix(train_code$data[,-1])\n",
        "\n",
        "lookback <- 10    # Número de pasos de tiempo que se toman (k).\n",
        "batch_size <- 264 # Tamaño de batch de datos de la función generadora\n",
        "delay <- 1        # Número de pasos de tiempo hacia el futuro para target\n",
        "min_index <- 1    # Posición de inicio de las lecuras de series.\n",
        "predseries <- 1   # Posición en la que se encuentra la variable target.\n",
        "\n",
        "train_k <-  create_lstm_data.2(\n",
        "    data = train_data,\n",
        "    lookback = lookback,\n",
        "    delay = delay,\n",
        "    batch_size = batch_size,\n",
        "    min_index = min_index,\n",
        "    max_index = NULL,\n",
        "    predseries = predseries)\n",
        "\n",
        "# Cálculo del número de steps de training:\n",
        "train_steps <- round((nrow(train_data)-lookback) / batch_size)"
      ],
      "metadata": {
        "id": "OBQuxMbwxNJJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data <- as.matrix(val_code$data[,-1])\n",
        "\n",
        "val_k <- create_lstm_data.2(\n",
        "    data = val_data,\n",
        "    lookback = lookback,\n",
        "    delay = delay,\n",
        "    batch_size = batch_size,\n",
        "    min_index = min_index,\n",
        "    max_index = NULL,\n",
        "    predseries = predseries)\n",
        "\n",
        "# Cálculo del número de steps de training:\n",
        "val_steps <- round((nrow(val_data)-lookback) / batch_size)"
      ],
      "metadata": {
        "id": "BmDln73lxNTs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data <- as.matrix(test_code$data[,-1])\n",
        "\n",
        "test_k <-  create_lstm_data.2(\n",
        "    data = test_data,\n",
        "    lookback = lookback,\n",
        "    delay = delay,\n",
        "    batch_size = batch_size,\n",
        "    min_index = min_index,\n",
        "    max_index = NULL,\n",
        "    predseries = predseries)\n",
        "\n",
        "\n",
        "# Cálculo del número de steps de training:\n",
        "test_steps <- round((nrow(test_data)-lookback) / batch_size)"
      ],
      "metadata": {
        "id": "rkQjvAJhxNt_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funciones Wrapper"
      ],
      "metadata": {
        "id": "bJbmM-G4hTXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wrap_train <- function() {\n",
        "  seq <- NULL\n",
        "\n",
        "  while (is.null(seq)) {\n",
        "    tryCatch(\n",
        "      seq <- train_k(),\n",
        "      error = function(e) {\n",
        "        warning(\"Empty sequence error occurred. Trying the next one.\")\n",
        "        return(NULL)  # Devuelve NULL si ocurre un error en la función\n",
        "                      # generadora y continúa el loop while.\n",
        "      }\n",
        "    )\n",
        "  }\n",
        "\n",
        "  tensor_list <- list(\n",
        "    list(seq[[1]][, , 1, drop = FALSE],\n",
        "         seq[[1]][, lookback, -1]),\n",
        "    list(seq[[2]])\n",
        "  )\n",
        "\n",
        "  return(tensor_list)\n",
        "}"
      ],
      "metadata": {
        "id": "wFCCznArhPsC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrap_val <- function() {\n",
        "  seq <- NULL\n",
        "\n",
        "  while (is.null(seq)) {\n",
        "    tryCatch(\n",
        "      seq <- val_k(),\n",
        "      error = function(e) {\n",
        "        warning(\"Empty sequence error occurred. Trying the next one.\")\n",
        "        return(NULL)  # Devuelve NULL si ocurre un error en la función\n",
        "                      # generadora y continúa el loop while.\n",
        "      }\n",
        "    )\n",
        "  }\n",
        "\n",
        "  tensor_list <- list(\n",
        "    list(seq[[1]][, , 1, drop = FALSE],\n",
        "         seq[[1]][, lookback, -1]),\n",
        "    list(seq[[2]])\n",
        "  )\n",
        "\n",
        "  return(tensor_list)\n",
        "}"
      ],
      "metadata": {
        "id": "Z3uVv2AAhP3e"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrap_test <- function() {\n",
        "  seq <- NULL\n",
        "\n",
        "  while (is.null(seq)) {\n",
        "    tryCatch(\n",
        "      seq <- test_k(),\n",
        "      error = function(e) {\n",
        "        warning(\"Empty sequence error occurred. Trying the next one.\")\n",
        "        return(NULL)  # Devuelve NULL si ocurre un error en la función\n",
        "                      # generadora y continúa el loop while.\n",
        "      }\n",
        "    )\n",
        "  }\n",
        "\n",
        "  tensor_list <- list(\n",
        "    list(seq[[1]][, , 1, drop = FALSE],\n",
        "         seq[[1]][, lookback, -1]),\n",
        "    list(seq[[2]])\n",
        "  )\n",
        "\n",
        "  return(tensor_list)\n",
        "}"
      ],
      "metadata": {
        "id": "64USfIPRhQCa"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN LSTM condicional"
      ],
      "metadata": {
        "id": "V8kXyE8ee2D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros para definir el modelo:\n",
        "\n",
        "dynamic_features = 1 # Variables dinámicas (QC_RESULT)\n",
        "static_features = 3  # Variables estáticas (ANALIZADOR, CODIGO_PRUEBA Y                                              NIVEL)\n",
        "lstm_units = 32      # Número de unidades en la capa LSTM\n",
        "vocabulary_size = 32 # Número de niveles codificados de las variables                           estáticas.\n",
        "epochs <- 15\n",
        "optimizer <- \"adam\"\n",
        "loss <- \"mae\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5ErUajWacQZ",
        "outputId": "406e9966-9979-47bd-847f-9b42a8c7b506"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "________________________________________________________________________________\n",
            " Layer (type)                       Output Shape                    Param #     \n",
            "================================================================================\n",
            " lstm_11 (LSTM)                     (None, 10)                      1760        \n",
            " dense_11 (Dense)                   (None, 1)                       11          \n",
            "================================================================================\n",
            "Total params: 1,771\n",
            "Trainable params: 1,771\n",
            "Non-trainable params: 0\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para crear el modelo:\n",
        "\n",
        "conditional_lstm <- function(rnn_units, vocabulary_size,\n",
        "                             dynamic_features, static_features, epochs,\n",
        "                             number_sequence){\n",
        "  # Modelo LSTM:\n",
        "\n",
        "  # Capa de entrada de datos dinámicos:\n",
        "  dynamic_input_layer <- layer_input(shape =\n",
        "                                       c(lookback, dynamic_features),\n",
        "                                     name = \"dynamic_input_layer\")\n",
        "  #dynamic_input_layer <- layer_masking(mask_value =\n",
        "                                         #-99999)(dynamic_input_layer)\n",
        "  # Capa de entrada de datos estáticos:\n",
        "  static_input_layer <- layer_input(shape = static_features,\n",
        "                                    name = \"static_input_layer\")\n",
        "\n",
        "  # Capa a de embedding para los datos estáticos:\n",
        "  embedding_layer <- layer_embedding(\n",
        "    input_dim = vocabulary_size,\n",
        "    output_dim = lstm_units)(static_input_layer)\n",
        "\n",
        "  # Capa lambda para seleccionar los embeddings que modificarán los estados ocultos de la capa LSTM:\n",
        "  embedding_layer <- layer_lambda(f = \\(x) x[,1,],\n",
        "                          name = \"lambda_embeddings\")(embedding_layer)\n",
        "\n",
        "  # Capa LSTM que recibe dps valores de estado oculto de la capa de embeddings con la información de las variables estáticas:\n",
        "  lstm_layer <- layer_lstm(units = lstm_units,\n",
        "                           name = \"lstm_1\",\n",
        "                           dropout = 0.3,\n",
        "                           recurrent_dropout = 0.3,\n",
        "                           kernel_regularizer = regularizer_l2(l=0.01),\n",
        "                           return_sequences = F,)(dynamic_input_layer,\n",
        "                                                  initial_state = list(\n",
        "                                                    embedding_layer,\n",
        "                                                    embedding_layer))\n",
        "\n",
        "  # Capa de salida con una unidad de activación lineal para la predicción:\n",
        "  output_layer <- layer_dense(units = 1,\n",
        "                              activation = \"linear\",\n",
        "                              name = \"output_layer\")(lstm_layer)\n",
        "\n",
        "  # Compilación:\n",
        "\n",
        "  model <-\n",
        "    keras_model(\n",
        "      inputs  = list(dynamic_input_layer, static_input_layer),\n",
        "      outputs = list(output_layer)\n",
        "      ) %>%\n",
        "    compile(\n",
        "      optimizer = optimizer,\n",
        "      loss      = loss,\n",
        "      metrics = list(\"mae\",\n",
        "                   \"mse\",\n",
        "                   rmse\n",
        "                   )\n",
        "    )\n",
        "\n",
        "  summary(model)\n",
        "\n",
        "  # Guardar modelo naïve\n",
        "\n",
        "  file_name <- paste0(\"lstm_QC_\", number_sequence, \".keras\")\n",
        "\n",
        "  save_model_weights_hdf5(model,\n",
        "                          file.path(resultsdir, \"naive_model.h5\"),\n",
        "                          overwrite = T)\n",
        "\n",
        "  # Callbacks\n",
        "\n",
        "  callbacks <- list(\n",
        "  callback_tensorboard(log_dir=file.path(resultsdir, \"run_a\")\n",
        "                      # write_grads = T,\n",
        "                      # histogram_freq = 1,\n",
        "                      # update_freq = \"batch\",\n",
        "                      # write_images = T\n",
        "                      ),\n",
        "  callback_model_checkpoint(file.path(resultsdir, file_name),\n",
        "                            monitor = \"rmse\",\n",
        "                            mode = \"min\",\n",
        "                            verbose=1,\n",
        "                            save_best_only = T,\n",
        "                            save_weights_only = T),\n",
        "  callback_reduce_lr_on_plateau(monitor = \"val_loss\", factor = 0.1,\n",
        "                                patience = 10, min_lr = 0.000001),\n",
        "  callback_early_stopping(monitor = \"val_loss\", patience = 20,\n",
        "                          verbose = 1)\n",
        "  )\n",
        "\n",
        "   # Training\n",
        "  history <- model %>%\n",
        "    fit(wrap_train,\n",
        "        epochs = epochs,\n",
        "        steps_per_epoch = train_steps,\n",
        "        validation_data = wrap_val,\n",
        "        validation_steps = val_steps,\n",
        "        callbacks = callbacks\n",
        "        )\n",
        "\n",
        "  plot(history)\n",
        "\n",
        "  return(model)\n",
        "}"
      ],
      "metadata": {
        "id": "2Ur699oBhlhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K <- keras::backend()\n",
        "\n",
        "rmse <- function(y_pred, y_true) {\n",
        "  sq_diff <- K$square(y_pred - y_true)\n",
        "  mean_sq_diff <- K$mean(sq_diff)\n",
        "  rmse_value <- K$sqrt(mean_sq_diff)\n",
        "  return(rmse_value)\n",
        "}\n",
        "\n",
        "attr(rmse, \"py_function_name\") <- \"rmse\"\n"
      ],
      "metadata": {
        "id": "c3xH6Z3SiqcJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(123)\n",
        "model_0 <- conditional_lstm(dynamic_features = dynamic_features,\n",
        "                 static_features = static_features,\n",
        "                 vocabulary_size = vocabulary_size,\n",
        "                 epochs = 15,\n",
        "                 number_sequence = 1)"
      ],
      "metadata": {
        "id": "cfcPLr_zisli"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimización"
      ],
      "metadata": {
        "id": "NnvA3XjNipGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(tfruns)\n",
        "runs <- tuning_run(\"LSTM_QC_script.R\",\n",
        "                   runs_dir = file.path(resultsdir, \"lb_units_regul\"),\n",
        "                   sample = 0.5,\n",
        "                   flags = list(\n",
        "                     lookback = c(5, 10, 20),\n",
        "                     batch_size = c(32, 64, 128),\n",
        "                     lstm_units= c(8, 12, 16),\n",
        "                     dropout1 = c(0.3, 0.8),\n",
        "                     recurrent_dropout1 = c(0.1, 0.4, 0.8),\n",
        "                     L2regularizer1 = c(0.01, 0.001)\n",
        "                   ))\n",
        "\n",
        "runs[order(runs$eval_acc, decreasing = TRUE), ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7g6glA6-poUO",
        "outputId": "04262f9c-035e-4f4c-e236-951fe4b0e9d8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "324 total combinations of flags \n",
            "\n",
            "(sampled to 162 combinations)\n",
            "\n",
            "\n",
            "Training run 1/162 (flags = list(10, 64, 8, 0.8, 0.4, 0.001)) \n",
            "\n",
            "Using run directory /content/Resultados/lb_units_regul/2023-06-17T06-42-49Z\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> library(tfruns)\n",
            "\n",
            "> library(keras)\n",
            "\n",
            "> FLAGS <- flags(flag_numeric(\"lookback\", 10), flag_numeric(\"lstm_units\", \n",
            "+     8), flag_numeric(\"dropout1\", 0.1), flag_numeric(\"recurrent_dropout1\", .... [TRUNCATED] \n",
            "\n",
            "> train_data <- as.matrix(train_code$data[, -1])\n",
            "\n",
            "> lookback <- FLAGS$lookback\n",
            "\n",
            "> batch_size <- FLAGS$batch_size\n",
            "\n",
            "> delay <- 1\n",
            "\n",
            "> min_index <- 1\n",
            "\n",
            "> predseries <- 1\n",
            "\n",
            "> train_k <- create_lstm_data.2(data = train_data, lookback = lookback, \n",
            "+     delay = delay, batch_size = batch_size, min_index = min_index, \n",
            "+     m .... [TRUNCATED] \n",
            "\n",
            "> train_steps <- round((nrow(train_data) - lookback)/batch_size)\n",
            "\n",
            "> wrap_train <- function() {\n",
            "+     seq <- NULL\n",
            "+     while (is.null(seq)) {\n",
            "+         tryCatch(seq <- train_k(), error = function(e) {\n",
            "+             w .... [TRUNCATED] \n",
            "\n",
            "> val_data <- as.matrix(val_code$data[, -1])\n",
            "\n",
            "> val_k <- create_lstm_data.2(data = val_data, lookback = lookback, \n",
            "+     delay = delay, batch_size = batch_size, min_index = min_index, \n",
            "+     max_i .... [TRUNCATED] \n",
            "\n",
            "> val_steps <- round((nrow(val_data) - lookback)/batch_size)\n",
            "\n",
            "> wrap_val <- function() {\n",
            "+     seq <- NULL\n",
            "+     while (is.null(seq)) {\n",
            "+         tryCatch(seq <- val_k(), error = function(e) {\n",
            "+             warni .... [TRUNCATED] \n",
            "\n",
            "> test_data <- as.matrix(test_code$data[, -1])\n",
            "\n",
            "> test_k <- create_lstm_data.2(data = test_data, lookback = lookback, \n",
            "+     delay = delay, batch_size = batch_size, min_index = min_index, \n",
            "+     max .... [TRUNCATED] \n",
            "\n",
            "> wrap_test <- function() {\n",
            "+     seq <- NULL\n",
            "+     while (is.null(seq)) {\n",
            "+         tryCatch(seq <- test_k(), error = function(e) {\n",
            "+             war .... [TRUNCATED] \n",
            "\n",
            "> test_steps <- round((nrow(test_data) - lookback)/batch_size)\n",
            "\n",
            "> dynamic_features = 1\n",
            "\n",
            "> static_features = 3\n",
            "\n",
            "> lstm_units = FLAGS$lstm_units\n",
            "\n",
            "> vocabulary_size = 32\n",
            "\n",
            "> epochs <- 50\n",
            "\n",
            "> optimizer <- \"adam\"\n",
            "\n",
            "> loss <- \"mae\"\n",
            "\n",
            "> dynamic_input_layer <- layer_input(shape = c(lookback, \n",
            "+     dynamic_features), name = \"dynamic_input_layer\")\n",
            "\n",
            "> static_input_layer <- layer_input(shape = static_features, \n",
            "+     name = \"static_input_layer\")\n",
            "\n",
            "> embedding_layer <- layer_embedding(input_dim = vocabulary_size, \n",
            "+     output_dim = lstm_units)(static_input_layer)\n",
            "\n",
            "> embedding_layer <- layer_lambda(f = function(x) x[, \n",
            "+     1, ], name = \"lambda_embeddings\")(embedding_layer)\n",
            "\n",
            "> lstm_layer <- layer_lstm(units = lstm_units, name = \"layer_lstm\", \n",
            "+     dropout = FLAGS$dropout1, recurrent_dropout = FLAGS$recurrent_dropout1, \n",
            "+  .... [TRUNCATED] \n",
            "\n",
            "> output_layer <- layer_dense(units = 1, activation = \"linear\", \n",
            "+     name = \"output_layer\")(lstm_layer)\n",
            "\n",
            "> model <- keras_model(inputs = list(dynamic_input_layer, \n",
            "+     static_input_layer), outputs = list(output_layer))\n",
            "\n",
            "> model %<>% compile(optimizer = optimizer, loss = loss, \n",
            "+     metrics = list(\"mae\", \"mse\", rmse))\n",
            "\n",
            "> file_name <- paste0(\"lstm_QC_\", 0, \".keras\")\n",
            "\n",
            "> save_model_weights_hdf5(model, file.path(resultsdir, \n",
            "+     \"naive_model.h5\"), overwrite = T)\n",
            "\n",
            "> callbacks <- list(callback_model_checkpoint(file.path(resultsdir, \n",
            "+     file_name), monitor = \"rmse\", mode = \"min\", verbose = 1, \n",
            "+     save_best_o .... [TRUNCATED] \n",
            "\n",
            "> K <- keras::backend()\n",
            "\n",
            "> rmse <- function(y_pred, y_true) {\n",
            "+     sq_diff <- K$square(y_pred - y_true)\n",
            "+     mean_sq_diff <- K$mean(sq_diff)\n",
            "+     rmse_value <- K$sqrt(mean_ .... [TRUNCATED] \n",
            "\n",
            "> attr(rmse, \"py_function_name\") <- \"rmse\"\n",
            "\n",
            "> history <- model %>% fit(wrap_train, epochs = epochs, \n",
            "+     steps_per_epoch = train_steps, validation_data = wrap_val, \n",
            "+     validation_steps = va .... [TRUNCATED] \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Traceback:\n",
            "1. tuning_run(\"LSTM_QC_script.R\", runs_dir = file.path(resultsdir, \n .     \"lb_units_regul\"), sample = 0.5, flags = list(lookback = c(5, \n .     10, 20), batch_size = c(32, 64, 128), lstm_units = c(8, 12, \n .     16), dropout1 = c(0.3, 0.8), recurrent_dropout1 = c(0.1, \n .     0.4, 0.8), L2regularizer1 = c(0.01, 0.001)))",
            "2. training_run(file = file, config = config, flags = flags, properties = properties, \n .     run_dir = NULL, artifacts_dir = artifacts_dir, echo = echo, \n .     view = FALSE, envir = new.env(parent = envir), encoding = encoding)",
            "3. do_training_run(file, run_dir, artifacts_dir, echo = echo, envir = envir, \n .     encoding = encoding)",
            "4. with_changed_file_copy(artifacts_dir, run_dir, {\n .     write_run_property(\"script\", basename(file))\n .     write_run_property(\"start\", as.double(Sys.time()))\n .     on.exit(write_run_property(\"end\", as.double(Sys.time())), \n .         add = TRUE)\n .     on.exit(clear_run(), add = TRUE)\n .     on.exit(reset_tf_graph(), add = TRUE)\n .     old_width <- getOption(\"width\")\n .     options(width = min(100, old_width))\n .     on.exit(options(width = old_width), add = TRUE)\n .     properties_dir <- file.path(meta_dir(run_dir), \"properties\")\n .     output_file <- file(file.path(properties_dir, \"output\"), \n .         open = \"wt\", encoding = \"UTF-8\")\n .     sink(file = output_file, type = \"output\", split = TRUE)\n .     on.exit({\n .         sink(type = \"output\")\n .         close(output_file)\n .     }, add = TRUE)\n .     plots_dir <- file.path(run_dir, \"plots\")\n .     if (!utils::file_test(\"-d\", plots_dir)) \n .         dir.create(plots_dir, recursive = TRUE)\n .     png_args <- list(filename = file.path(plots_dir, \"Rplot%03d.png\"), \n .         width = 1200, height = 715, res = 192)\n .     if (is_windows() && capabilities(\"cairo\")) \n .         png_args$type <- \"cairo\"\n .     do.call(grDevices::png, png_args)\n .     dev_number <- grDevices::dev.cur()\n .     on.exit(grDevices::dev.off(dev_number), add = TRUE)\n .     message(\"Using run directory \", run_dir)\n .     write_run_property(\"completed\", FALSE)\n .     withCallingHandlers({\n .         source(file = file, local = envir, echo = echo, encoding = encoding)\n .         write_run_property(\"completed\", TRUE)\n .     }, error = function(e) {\n .         write_run_metadata(\"error\", list(message = e$message, \n .             traceback = capture_stacktrace(sys.calls())))\n .         stop(e)\n .     })\n . })",
            "5. force(expr)",
            "6. withCallingHandlers({\n .     source(file = file, local = envir, echo = echo, encoding = encoding)\n .     write_run_property(\"completed\", TRUE)\n . }, error = function(e) {\n .     write_run_metadata(\"error\", list(message = e$message, traceback = capture_stacktrace(sys.calls())))\n .     stop(e)\n . })",
            "7. source(file = file, local = envir, echo = echo, encoding = encoding)",
            "8. withVisible(eval(ei, envir))",
            "9. eval(ei, envir)",
            "10. eval(ei, envir)",
            "11. model %>% fit(wrap_train, epochs = epochs, steps_per_epoch = train_steps, \n  .     validation_data = wrap_val, validation_steps = val_steps, \n  .     callbacks = callbacks)",
            "12. fit(., wrap_train, epochs = epochs, steps_per_epoch = train_steps, \n  .     validation_data = wrap_val, validation_steps = val_steps, \n  .     callbacks = callbacks)",
            "13. fit.keras.engine.training.Model(., wrap_train, epochs = epochs, \n  .     steps_per_epoch = train_steps, validation_data = wrap_val, \n  .     validation_steps = val_steps, callbacks = callbacks)",
            "14. do.call(object$fit, args)",
            "15. (structure(function (x = NULL, y = NULL, batch_size = NULL, epochs = 1L, \n  .     verbose = \"auto\", callbacks = NULL, validation_split = 0, \n  .     validation_data = NULL, shuffle = TRUE, class_weight = NULL, \n  .     sample_weight = NULL, initial_epoch = 0L, steps_per_epoch = NULL, \n  .     validation_steps = NULL, validation_batch_size = NULL, validation_freq = 1L, \n  .     max_queue_size = 10L, workers = 1L, use_multiprocessing = FALSE) \n  . {\n  .     cl <- sys.call()\n  .     cl[[1L]] <- list2\n  .     call_args <- split_named_unnamed(eval(cl, parent.frame()))\n  .     result <- py_call_impl(callable, call_args$unnamed, call_args$named)\n  .     if (convert) \n  .         result <- py_to_r(result)\n  .     if (is.null(result)) \n  .         invisible(result)\n  .     else result\n  . }, class = c(\"python.builtin.method\", \"python.builtin.object\"\n  . ), py_object = <environment>))(batch_size = NULL, epochs = 50L, \n  .     verbose = \"auto\", validation_split = 0, shuffle = TRUE, class_weight = NULL, \n  .     sample_weight = NULL, initial_epoch = 0L, x = <environment>, \n  .     validation_data = <environment>, steps_per_epoch = 940L, \n  .     validation_steps = 317L, callbacks = list(<environment>, \n  .         <environment>, <environment>, <environment>, <environment>, \n  .         <environment>, <environment>))",
            "16. py_call_impl(callable, call_args$unnamed, call_args$named)",
            "17. stop(<environment>)",
            "18. (function (e) \n  . {\n  .     write_run_metadata(\"error\", list(message = e$message, traceback = capture_stacktrace(sys.calls())))\n  .     stop(e)\n  . })(<environment>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip(zipfile = 'tfruns_1', files = 'Resultados/lb_units_regul')"
      ],
      "metadata": {
        "id": "dluwabHtGAj8"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimización de hiperparámetros usando tfruns"
      ],
      "metadata": {
        "id": "snbhdcqxzzlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runs <- tuning_run(\"LSTM_QC_script.R\",\n",
        "                   runs_dir = file.path(resultsdir, \"lb&units&regul\"),\n",
        "                   sample = 0.5,\n",
        "                   flags = list(\n",
        "                     lookback = c(5, 10, 20),\n",
        "                     batch_size = c(32, 64, 128),\n",
        "                     lstm_units= c(8, 12, 16),\n",
        "                     dropout1 = c(0.3, 0.8),\n",
        "                     recurrent_dropout1 = c(0.1, 0.4, 0.8),\n",
        "                     L2regularizer1 = c(0.01, 0.001)\n",
        "\n",
        "))\n",
        "\n",
        "runs[order(runs$eval_acc, decreasing = TRUE), ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbr4UaB-t5cx",
        "outputId": "34d8792b-e4c4-44aa-8cb3-0bab7c1790d3"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘listenv’, ‘parallelly’, ‘future’, ‘globals’, ‘shape’, ‘future.apply’, ‘numDeriv’, ‘progressr’, ‘SQUAREM’, ‘diagram’, ‘lava’, ‘prodlim’, ‘proxy’, ‘iterators’, ‘clock’, ‘gower’, ‘hardhat’, ‘ipred’, ‘timeDate’, ‘e1071’, ‘foreach’, ‘ModelMetrics’, ‘plyr’, ‘pROC’, ‘recipes’, ‘reshape2’\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función generate_data se ejecutará en cada iteración de fit_tuner, garantizando que las funciones generadoras se llamen nuevamente para obtener nuevos conjuntos de datos en cada iteración.\n"
      ],
      "metadata": {
        "id": "AGfayfdlRTRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validación cruzada Day Forward Chain"
      ],
      "metadata": {
        "id": "MIAKczot0E10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestra de validación:\n",
        "forward_chain_cv <- function(s){\n",
        "  # quantiles dependientes del número de divisiones que se pase (s):\n",
        "  q <- seq(1/s, 1, 1/s)\n",
        "\n",
        "  # Cálculo de las fechas correspondientes a cada cuantil\n",
        "  time_points <-\n",
        "    do.call(quantile,\n",
        "            list(as.POSIXct(as.Date(qc_data_sel_wl[[1]])), q))\n",
        "\n",
        "  # Listas para conener las funciones generadoras\n",
        "  train_ks <- list()\n",
        "  val_ks <- list()\n",
        "\n",
        "  # Vectores para guardar el número de steps de cada cadena:\n",
        "  train_cvsteps <- c()\n",
        "  val_cvsteps <- c()\n",
        "\n",
        "  # Loop a lo largo de los percentiles de tiempo:\n",
        "  for(i in 1:(length(time_points)-1)){\n",
        "\n",
        "  # Workflow aplicado a cada forward chain:\n",
        "\n",
        "    train_n <- qc_data_sel_wl %>%\n",
        "      subset(.[[1]] < time_points[i]) %>%\n",
        "      normalize_train(.)\n",
        "\n",
        "    val_n <- qc_data_sel_wl %>%\n",
        "      subset(.[[1]] > time_points[i] & .[[1]] <= time_points[i+1]) %>%\n",
        "      norm_test_val(., means = train_n$means, stds = train_n$stdev)\n",
        "    ###################################################################\n",
        "    train_code <- code_cat_var(train_n$scaled_data[,-c(3:16, 19)])\n",
        "    val_code <- code_cat_var(val_n[,-c(3:16, 19)])\n",
        "    ###################################################################\n",
        "\n",
        "    # Crear una lista de funciones generadoras para cada cadena:\n",
        "\n",
        "    train_k <- create_lstm_data.2(\n",
        "        data = as.matrix(train_code$data[,-1]),\n",
        "        lookback = lookback,\n",
        "        delay = delay,\n",
        "        batch_size = batch_size,\n",
        "        min_index = 1,\n",
        "        max_index = NULL,\n",
        "        predseries = predseries)\n",
        "\n",
        "    train_cvsteps <- rbind(train_cvsteps,\n",
        "                           round((nrow(train_code$data)-lookback) /\n",
        "                                   batch_size))\n",
        "\n",
        "    val_k <- create_lstm_data.2(\n",
        "        data = as.matrix(val_code$data[,-1]),\n",
        "        lookback = lookback,\n",
        "        delay = delay,\n",
        "        batch_size = batch_size,\n",
        "        min_index = 1,\n",
        "        max_index = NULL,\n",
        "        predseries = predseries)\n",
        "\n",
        "    val_cvsteps <- rbind(val_cvsteps,\n",
        "                         round((nrow(val_data)-lookback) / batch_size))\n",
        "\n",
        "    train_ks[[i]] <- train_k\n",
        "\n",
        "    val_ks[[i]] <- val_k\n",
        "\n",
        "    train_ks %>% setNames(paste0(\"train_\", i, sep = \"\"))\n",
        "  }\n",
        "\n",
        "  chain <- list(train_ks, val_ks)\n",
        "  names(chain) <- c(\"train\", \"val\")\n",
        "  chain$trainst <- train_cvsteps\n",
        "  chain$valst <- val_cvsteps\n",
        "\n",
        "  return(chain)\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "tZNa2Il0xyT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain <- forward_chain_cv(4)"
      ],
      "metadata": {
        "id": "w0YCIFLnx00g",
        "outputId": "ea0d6c93-4681-47b7-ef78-083bcc43a70f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1m\u001b[22m`summarise()` has grouped output by 'ANALIZADOR'. You can override using the\n",
            "`.groups` argument.\n",
            "\u001b[1m\u001b[22m`summarise()` has grouped output by 'ANALIZADOR'. You can override using the\n",
            "`.groups` argument.\n",
            "\u001b[1m\u001b[22m`summarise()` has grouped output by 'ANALIZADOR'. You can override using the\n",
            "`.groups` argument.\n",
            "\u001b[1m\u001b[22m`summarise()` has grouped output by 'ANALIZADOR'. You can override using the\n",
            "`.groups` argument.\n",
            "\u001b[1m\u001b[22m`summarise()` has grouped output by 'ANALIZADOR'. You can override using the\n",
            "`.groups` argument.\n",
            "\u001b[1m\u001b[22m`summarise()` has grouped output by 'ANALIZADOR'. You can override using the\n",
            "`.groups` argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history <- list()\n",
        "\n",
        "for (i in 1:length(chain$train)) {\n",
        "\n",
        "  file_name <- paste0(\"lstm_QC_\", i, \".cv\")\n",
        "  model <- model_0\n",
        "\n",
        "\n",
        "  history[[i]] <- model_0 %>%\n",
        "    fit_generator(\n",
        "      generator = chain$train[[i]],\n",
        "      steps_per_epoch = chain$trainst[[i]],\n",
        "      epochs = 1,\n",
        "      validation_data = chain$val[[i]],\n",
        "      validation_steps = chain$valst[[i]],\n",
        "      callbacks = callbacks\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "n5tXwl0cx3qr",
        "outputId": "d513cc2c-13f7-4c97-92e1-a72ae57754fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message in fit_generator(., generator = chain$train[[i]], steps_per_epoch = chain$trainst[[i]], :\n",
            "“`fit_generator` is deprecated. Use `fit` instead, it now accept generators.”\n",
            "Warning message in fit_generator(., generator = chain$train[[i]], steps_per_epoch = chain$trainst[[i]], :\n",
            "“`fit_generator` is deprecated. Use `fit` instead, it now accept generators.”\n",
            "Error occurred in generator: subscript out of bounds\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "generator raised StopIterationTraceback:\n",
            "1. model_0 %>% fit_generator(generator = chain$train[[i]], steps_per_epoch = chain$trainst[[i]], \n .     epochs = 1, validation_data = chain$val[[i]], validation_steps = chain$valst[[i]], \n .     callbacks = callbacks)",
            "2. fit_generator(., generator = chain$train[[i]], steps_per_epoch = chain$trainst[[i]], \n .     epochs = 1, validation_data = chain$val[[i]], validation_steps = chain$valst[[i]], \n .     callbacks = callbacks)",
            "3. do.call(fit, args)",
            "4. (function (object, ...) \n . {\n .     UseMethod(\"fit\")\n . })(object = structure(function (object, ...) \n . {\n .     compose_layer(object, x, ...)\n . }, class = c(\"keras.engine.sequential.Sequential\", \"keras.engine.functional.Functional\", \n . \"keras.engine.training.Model\", \"keras.engine.base_layer.Layer\", \n . \"tensorflow.python.module.module.Module\", \"tensorflow.python.trackable.autotrackable.AutoTrackable\", \n . \"tensorflow.python.trackable.base.Trackable\", \"keras.utils.version_utils.LayerVersionSelector\", \n . \"keras.utils.version_utils.ModelVersionSelector\", \"python.builtin.object\"\n . ), py_object = <environment>), x = function () \n . {\n .     if (shuffle) {\n .         rows <- sample(c((min_index + lookback):max_index), size = batch_size)\n .     }\n .     else {\n .         if (i + batch_size >= max_index) \n .             i <<- min_index + lookback\n .         rows <- c(i:min(i + batch_size, max_index))\n .         i <<- i + length(rows)\n .     }\n .     samples <- array(0, dim = c(length(rows), lookback/step, \n .         dim(data)[[-1]]))\n .     targets <- array(0, dim = c(length(rows)))\n .     for (j in 1:length(rows)) {\n .         indices <- seq(rows[[j]] - lookback, rows[[j]], length.out = dim(samples)[[2]])\n .         samples[j, , ] <- data[indices, ]\n .         targets[[j]] <- data[rows[[j]] + delay, predseries]\n .     }\n .     list(samples, targets)\n . }, steps_per_epoch = 400, epochs = 1, verbose = 1, callbacks = list(\n .     <environment>, <environment>, <environment>, <environment>), \n .     validation_data = function () \n .     {\n .         if (shuffle) {\n .             rows <- sample(c((min_index + lookback):max_index), \n .                 size = batch_size)\n .         }\n .         else {\n .             if (i + batch_size >= max_index) \n .                 i <<- min_index + lookback\n .             rows <- c(i:min(i + batch_size, max_index))\n .             i <<- i + length(rows)\n .         }\n .         samples <- array(0, dim = c(length(rows), lookback/step, \n .             dim(data)[[-1]]))\n .         targets <- array(0, dim = c(length(rows)))\n .         for (j in 1:length(rows)) {\n .             indices <- seq(rows[[j]] - lookback, rows[[j]], length.out = dim(samples)[[2]])\n .             samples[j, , ] <- data[indices, ]\n .             targets[[j]] <- data[rows[[j]] + delay, predseries]\n .         }\n .         list(samples, targets)\n .     }, validation_steps = 203, class_weight = NULL, max_queue_size = 10, \n .     workers = 1, initial_epoch = 0)",
            "5. fit.keras.engine.training.Model(object = structure(function (object, \n .     ...) \n . {\n .     compose_layer(object, x, ...)\n . }, class = c(\"keras.engine.sequential.Sequential\", \"keras.engine.functional.Functional\", \n . \"keras.engine.training.Model\", \"keras.engine.base_layer.Layer\", \n . \"tensorflow.python.module.module.Module\", \"tensorflow.python.trackable.autotrackable.AutoTrackable\", \n . \"tensorflow.python.trackable.base.Trackable\", \"keras.utils.version_utils.LayerVersionSelector\", \n . \"keras.utils.version_utils.ModelVersionSelector\", \"python.builtin.object\"\n . ), py_object = <environment>), x = function () \n . {\n .     if (shuffle) {\n .         rows <- sample(c((min_index + lookback):max_index), size = batch_size)\n .     }\n .     else {\n .         if (i + batch_size >= max_index) \n .             i <<- min_index + lookback\n .         rows <- c(i:min(i + batch_size, max_index))\n .         i <<- i + length(rows)\n .     }\n .     samples <- array(0, dim = c(length(rows), lookback/step, \n .         dim(data)[[-1]]))\n .     targets <- array(0, dim = c(length(rows)))\n .     for (j in 1:length(rows)) {\n .         indices <- seq(rows[[j]] - lookback, rows[[j]], length.out = dim(samples)[[2]])\n .         samples[j, , ] <- data[indices, ]\n .         targets[[j]] <- data[rows[[j]] + delay, predseries]\n .     }\n .     list(samples, targets)\n . }, steps_per_epoch = 400, epochs = 1, verbose = 1, callbacks = list(\n .     <environment>, <environment>, <environment>, <environment>), \n .     validation_data = function () \n .     {\n .         if (shuffle) {\n .             rows <- sample(c((min_index + lookback):max_index), \n .                 size = batch_size)\n .         }\n .         else {\n .             if (i + batch_size >= max_index) \n .                 i <<- min_index + lookback\n .             rows <- c(i:min(i + batch_size, max_index))\n .             i <<- i + length(rows)\n .         }\n .         samples <- array(0, dim = c(length(rows), lookback/step, \n .             dim(data)[[-1]]))\n .         targets <- array(0, dim = c(length(rows)))\n .         for (j in 1:length(rows)) {\n .             indices <- seq(rows[[j]] - lookback, rows[[j]], length.out = dim(samples)[[2]])\n .             samples[j, , ] <- data[indices, ]\n .             targets[[j]] <- data[rows[[j]] + delay, predseries]\n .         }\n .         list(samples, targets)\n .     }, validation_steps = 203, class_weight = NULL, max_queue_size = 10, \n .     workers = 1, initial_epoch = 0)",
            "6. do.call(object$fit, args)",
            "7. (structure(function (x = NULL, y = NULL, batch_size = NULL, epochs = 1L, \n .     verbose = \"auto\", callbacks = NULL, validation_split = 0, \n .     validation_data = NULL, shuffle = TRUE, class_weight = NULL, \n .     sample_weight = NULL, initial_epoch = 0L, steps_per_epoch = NULL, \n .     validation_steps = NULL, validation_batch_size = NULL, validation_freq = 1L, \n .     max_queue_size = 10L, workers = 1L, use_multiprocessing = FALSE) \n . {\n .     cl <- sys.call()\n .     cl[[1L]] <- list2\n .     call_args <- split_named_unnamed(eval(cl, parent.frame()))\n .     result <- py_call_impl(callable, call_args$unnamed, call_args$named)\n .     if (convert) \n .         result <- py_to_r(result)\n .     if (is.null(result)) \n .         invisible(result)\n .     else result\n . }, class = c(\"python.builtin.method\", \"python.builtin.object\"\n . ), py_object = <environment>))(batch_size = NULL, epochs = 1L, \n .     verbose = 1L, validation_split = 0, shuffle = TRUE, class_weight = NULL, \n .     sample_weight = NULL, initial_epoch = 0L, x = <environment>, \n .     validation_data = <environment>, steps_per_epoch = 400L, \n .     validation_steps = 203L, callbacks = list(<environment>, \n .         <environment>, <environment>, <environment>, <environment>, \n .         <environment>, <environment>))",
            "8. py_call_impl(callable, call_args$unnamed, call_args$named)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history <- list()\n",
        "\n",
        "for (i in 1:length(chain$train)) {\n",
        "\n",
        "  # Cargamos el modelo naive sin entrenar:\n",
        "  model <- load_model_hdf5(file.path(resultsdir,\"naive_model\"),\n",
        "                         custom_objects = list(\"rmse\" = rmse),\n",
        "                         compile = T)\n",
        "  file_name <- paste0(\"lstm_QC_\", i, \".cv\")\n",
        "  # Entrenamos\n",
        "  history[[i]] <- model %>%\n",
        "    fit_generator(\n",
        "      generator = chain$train[[i]],\n",
        "      steps_per_epoch = chain$trainst[[i]],\n",
        "      epochs = 15,\n",
        "      validation_data = chain$val[[i]],\n",
        "      validation_steps = chain$valst[[i]],\n",
        "      callbacks = list(\n",
        "  callback_tensorboard(log_dir=file.path(resultsdir, \"run_a\")\n",
        "                      # write_grads = T,\n",
        "                      # histogram_freq = 1,\n",
        "                      # update_freq = \"batch\",\n",
        "                      # write_images = T\n",
        "                      ),\n",
        "  callback_model_checkpoint(file.path(resultsdir, file_name),\n",
        "                            monitor= \"rmse\",\n",
        "                            mode=\"min\",\n",
        "                            verbose=1,\n",
        "                            save_best_only = TRUE),\n",
        "  callback_reduce_lr_on_plateau(monitor = \"val_loss\", factor = 0.1,\n",
        "                                patience = 10, min_lr = 0.000001),\n",
        "  callback_early_stopping(monitor = \"val_loss\", patience = 20,\n",
        "                          verbose = 1)\n",
        "  )\n",
        "    )\n",
        "  plot(history[[i]])\n",
        "}"
      ],
      "metadata": {
        "id": "hnhfvIzjjy99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(123)\n",
        "# Evaluación del modelo:\n",
        "path <- file.path(resultsdir, file_name)\n",
        "model <- load_model_hdf5(path,\n",
        "                         custom_objects = list(\"rmse\" =\n",
        "                                                 rmse),\n",
        "                         compile = T)\n",
        "evaluation_result <- evaluate(model_0, test_k, steps = test_steps)\n",
        "\n",
        "evaluation_result"
      ],
      "metadata": {
        "id": "SVb8NeM308M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_result <- evaluate(model_0, test_k, steps = test_steps)\n",
        "evaluation_result"
      ],
      "metadata": {
        "id": "fKbIjOHR1AVG",
        "outputId": "36c7abed-b6b5-4ff4-fc38-3c860ffd3dc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".dl-inline {width: auto; margin:0; padding: 0}\n",
              ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
              ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
              ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
              "</style><dl class=dl-inline><dt>loss</dt><dd>1.1914427280426</dd><dt>mae</dt><dd>0.951725244522095</dd><dt>mse</dt><dd>1.1914427280426</dd><dt>rmse</dt><dd>1.09004628658295</dd></dl>\n"
            ],
            "text/markdown": "loss\n:   1.1914427280426mae\n:   0.951725244522095mse\n:   1.1914427280426rmse\n:   1.09004628658295\n\n",
            "text/latex": "\\begin{description*}\n\\item[loss] 1.1914427280426\n\\item[mae] 0.951725244522095\n\\item[mse] 1.1914427280426\n\\item[rmse] 1.09004628658295\n\\end{description*}\n",
            "text/plain": [
              "     loss       mae       mse      rmse \n",
              "1.1914427 0.9517252 1.1914427 1.0900463 "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación"
      ],
      "metadata": {
        "id": "JlVtqFNDpnV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(123)\n",
        "# Evaluación del modelo:\n",
        "path <- file.path(resultsdir, file_name)\n",
        "model <- load_model_hdf5(path,\n",
        "                         custom_objects = list(\"rmse\" =\n",
        "                                                 rmse),\n",
        "                         compile = T)\n",
        "evaluation_result <- evaluate(model, test_k, steps = test_steps)\n",
        "\n",
        "evaluation_result\n"
      ],
      "metadata": {
        "id": "Kg18IT-pphlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Línea base de sentido común"
      ],
      "metadata": {
        "id": "b88_eUgAp1wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para calcular el MAE promedio para un modelo basado en predecir los targets del set de validación con las mismas muestras de validación, mediante la iteración de lotes de muestras. Esto sería equivalente a un modelo que predice el resultado futuro del QC con el actual y constituye el punto de partida para mejorar (common sense baseline).\n",
        "\n",
        "evaluate_naive_method <- function() {\n",
        "  batch_mae <- c()\n",
        "  batch_mse <- c()\n",
        "  batch_rmse <- c()\n",
        "  for (step in 1:val_steps) {\n",
        "    c(samples, targets) %<-% val_k()\n",
        "    preds <- samples[,dim(samples)[[2]],2]\n",
        "    mae <- mean(abs(preds - targets))\n",
        "    mse <- mean((preds - targets)^2)\n",
        "    rmse <- sqrt(mse)\n",
        "    batch_mae <- c(batch_mae, mae)\n",
        "    batch_mse <- c(batch_mse, mse)\n",
        "    batch_rmse <- c(batch_rmse, rmse)\n",
        "  }\n",
        "  naive_mse <- mean(batch_mse)\n",
        "  naive_mae <- mean(batch_mae)\n",
        "  naive_rmse <- mean(batch_rmse)\n",
        "  cat(\"naive_mae\", mae, \"\\n\",\n",
        "      \"naive_mse\", mse, \"\\n\",\n",
        "      \"naive_rmse\", rmse)\n",
        "  naive <- list(naive_mae, naive_mse, naive_rmse)\n",
        "  names(naive) <- c(\"mae\", \"mse\", \"rmse\")\n",
        "  return(naive)\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "# mae y mse del modelo naive:\n",
        "naive <- evaluate_naive_method()\n",
        "\n",
        "# mae del modelo LSTM:\n",
        "mae <- evaluation_result[2]\n",
        "\n",
        "eval_model <- cbind(train_n$stdev[[2]], train_n$stdev[[1]],\n",
        "                    train_n$stdev[[3]],\n",
        "                    naive$mae*train_n$stdev[[3]],\n",
        "                    mae*train_n$stdev[[3]])\n",
        "\n",
        "colnames(eval_model) <- c(\"CODIGO_PRUEBA\", \"ANALIZADOR\",\n",
        "                          \"SD\",\"NAIVE_MAE*SD\",\"MAE*SD\")\n",
        "\n",
        "# Imprimir los resultados de evaluación:\n",
        "\n",
        "sink(file.path(resultsdir, paste0(\"lstm_QC_\", format(Sys.time(),\n",
        "                                                    \"%Y%m%d_%H%M%S\"),\n",
        "                                  \".eval\")))\n",
        "\n",
        "naive\n",
        "evaluation_result\n",
        "eval_model\n",
        "\n",
        "# Cerrar el archivo de salida\n",
        "sink()\n"
      ],
      "metadata": {
        "id": "FcB0OUDZpx2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación por categorías.\n",
        "\n",
        "# Función para seleccionar los índices en test_indx que corresponden a una combinación determinada de CODIGO_PRUEBA, NIVEL Y ANALIZADOR:\n",
        "\n",
        "index_select <- function() {\n",
        "\n",
        "  # Opciones para elegir CLC, NIVEL y ANALIZADOR:\n",
        "  clc_opt <- test_code$levels$CODIGO_PRUEBA\n",
        "  level_opt <- test_code$levels$NIVEL\n",
        "  anal_opt <- test_code$levels$ANALIZADOR\n",
        "\n",
        "  # Introducción de la fecha por el usuario:\n",
        "  #date <- readline(\n",
        "   # \"fecha del día anterior a la predicción (aaaa-mm-dd): \")\n",
        "  #if(!date %in% as.Date(test_code$data$TIEMPO_QC))\n",
        "   #  print(\"fecha no incluida en dataset\")\n",
        "\n",
        "  # Introducción de prueba, nivel y analizador:\n",
        "  clc <- clc_opt[menu(clc_opt,\n",
        "                      title = \"Código CLC de prueba: \",\n",
        "                      graphics = T)]\n",
        "  level <- level_opt[menu(level_opt,\n",
        "                          title = \"Nivel de QC: \",\n",
        "                          graphics = T)]\n",
        "  anal <- anal_opt[menu(anal_opt,\n",
        "                        title = \"Analizador: \",\n",
        "                        graphics = T)]\n",
        "\n",
        "  cat(\"Indice correspondiente a la prueba: \", clc, \"\\n\",\n",
        "  \"nivel: \", level, \"\\n\",\n",
        "  \"analizador: \", anal, \"\\n\")\n",
        "\n",
        "  # Conversión de las variables introducidas en índice:\n",
        "\n",
        "  col_clc <- which(grepl(clc, names(test_indx)))-16\n",
        "  col_level <- which(grepl(paste0(\"NIVEL_\", level), names(test_indx)))-16\n",
        "  col_anal <- which(grepl(anal, names(test_indx)))-16\n",
        "  pos <- list(col_clc, col_level, col_anal)\n",
        "\n",
        "  code <- rep(0, length(categorical_vars+2))\n",
        "\n",
        "  for (i in seq_along(pos)) {\n",
        "    code[pos[[i]]] <- 1\n",
        "  }\n",
        "  code <- paste0(as.character(code), collapse = \"\")\n",
        "\n",
        "  index <- code_dictionary$index[match(code,\n",
        "                                       code_dictionary$code)]\n",
        "  print(index)\n",
        "  return(index)\n",
        "\n",
        "}\n",
        "\n",
        "index_pred <- index_select()\n",
        "\n",
        "  test_pred <- lapply(index_pred, function(idx) {\n",
        "    create_lstm_data.2(\n",
        "      data = as.matrix(test_indx[test_indx[,\"index\"] == idx,\n",
        "                                 -c(1, 3:16, length(test_indx))]),\n",
        "      lookback = lookback,\n",
        "      delay = delay,\n",
        "      batch_size = batch_size,\n",
        "      min_index = min_index,\n",
        "      max_index =\n",
        "      nrow(as.matrix(test_indx[test_indx[,\"index\"] == idx,]))-delay-1,\n",
        "      predseries = predseries)\n",
        "  }\n",
        "  )\n"
      ],
      "metadata": {
        "id": "WlhqqwBeqBP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las series y sus predicciones utilizando la función generadora de tests por categorías y obtener la predicción del modelo:\n",
        "x <- test_pred[[1]]()[[1]]\n",
        "y_pred <-  predict(model, x = x)\n",
        "y_true <- test_pred[[1]]()[[2]]\n",
        "\n",
        "metrics <- list(\n",
        "  MSE <- mse(actual = y_true, predicted = y_pred),\n",
        "  MAE <- mae(actual = y_true, predicted = y_pred),\n",
        "  Correlación <- cor(y_pred, y_true)\n",
        ")\n",
        "names(metrics) <- c(\"MSE\", \"MAE\", \"Coef. correlación\")\n",
        "metrics\n",
        "\n",
        "# Crear el gráfico de dispersión entre y_pred e y_true\n",
        "plot(y_true, y_pred, pch = 16, col = \"blue\", xlab = \"y_true\", ylab = \"y_pred\",\n",
        "     main = \"Gráfico de dispersión: y_true vs. y_pred\")\n",
        "\n",
        "# Calcular el coeficiente de correlación\n",
        "correlacion <- cor(y_true, y_pred)\n",
        "\n",
        "# Agregar el coeficiente de correlación al gráfico\n",
        "texto_cor <- paste(\"Correlación:\", round(correlacion, 2))\n",
        "mtext(texto_cor, side = 3, line = -2.5)\n"
      ],
      "metadata": {
        "id": "unqLfwmrqV0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular las métricas de todas las categorías:\n",
        "\n",
        "global_metrics <- list()\n",
        "\n",
        "for(i in seq_along(test_k)){\n",
        "\n",
        "  # Calcula x, y_true e y_pred a partir de la primera iteración de las funciones generadoras y el modelo:\n",
        "  x <- test_k[[i]]()[[1]]\n",
        "  y_true <- test_k[[i]]()[[2]]\n",
        "  y_pred <-  predict(model, x = x)\n",
        "\n",
        "  metrics <- list(\n",
        "  MSE <- mse(actual = y_true, predicted = y_pred),\n",
        "  MAE <- mae(actual = y_true, predicted = y_pred),\n",
        "  Correlación <- cor(y_pred, y_true)\n",
        "  )\n",
        "\n",
        "  names(metrics) <- c(\"MSE\", \"MAE\", \"Coef. correlación\")\n",
        "  global_metrics[[i]] <- metrics\n",
        "\n",
        "}\n",
        "\n",
        "names(global_metrics) <- index_values\n",
        "\n",
        "# Crear un gráfico para cada elemento de las sublistas en global_metrics\n",
        "for (i in 1:3) {\n",
        "  plot(1:length(global_metrics),\n",
        "       sapply(global_metrics, \"[[\", i),\n",
        "       pch = 16,\n",
        "       xlab = \"Index\",\n",
        "       ylab = names(global_metrics[[1]][i])\n",
        "  )\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "00Td3fbJqewO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para hacer la búsqueda inversa de analizador, prueba y nivel a partir de un index:\n",
        "\n",
        "reverse_index_select <- function(index) {\n",
        "  # Buscar el código correspondiente al índice\n",
        "  code <- code_dictionary$code[match(index, code_dictionary$index)]\n",
        "\n",
        "  # Extraer los dígitos de code\n",
        "  digits <- strsplit(code, \"\")[[1]]\n",
        "\n",
        "  # Encontrar las posiciones de los 1 en la secuencia de dígitos\n",
        "  pos_anal <- which(digits == \"1\")[1]\n",
        "  pos_clc <- which(digits == \"1\")[2]\n",
        "  pos_level <- which(digits == \"1\")[3]\n",
        "\n",
        "  # Obtener los valores de anal, clc y level\n",
        "  anal <- names(test_indx)[16 + pos_anal]\n",
        "  clc <- names(test_indx)[16 + pos_clc]\n",
        "  level <- names(test_indx)[16 + pos_level]\n",
        "\n",
        "  # Devolver los valores encontrados\n",
        "  result <- list(CÓDIGO_PRUEBA = substr(clc, 15, 22),\n",
        "                 NIVEL = level,\n",
        "                 ANALIZADOR = anal)\n",
        "  return(result)\n",
        "}\n"
      ],
      "metadata": {
        "id": "2gL7dGpaqm1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Búsqueda de casos con métricas por debajo de la media:\n",
        "\n",
        "limit_mse <- mse\n",
        "limit_mae <- mae\n",
        "limit_coef <- 0.7\n",
        "\n",
        "cases <- c()  # Lista para almacenar los índices\n",
        "\n",
        "for (i in seq_along(global_metrics)) {\n",
        "\n",
        "  sublist <- global_metrics[[i]]\n",
        "\n",
        "  # Extracción de métricas:\n",
        "  mse_i <- sublist$MSE\n",
        "  mae_i <- sublist$MAE\n",
        "  coef_i <- sublist$`Coef. correlación`\n",
        "\n",
        "  if (mse_i >= limit_mse & mae_i >= limit_mae &\n",
        "      coef_i <= limit_coef) {\n",
        "    cases <- c(cases, i)  # Agregar el índice a la lista\n",
        "  }\n",
        "}\n",
        "\n",
        "# Imprimir los índices encontrados\n",
        "\n",
        "print(cases)\n",
        "\n",
        "# Transformar índices a información de casos:\n",
        "\n",
        "selection <-list()\n",
        "\n",
        "for(i in seq_along(cases))\n",
        "selection[[i]] <- reverse_index_select(cases[i])\n",
        "\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "vAvOfEHaqtvV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}